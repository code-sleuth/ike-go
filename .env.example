# Turso Database Configuration
# Get these from your Turso dashboard at https://turso.tech/
TURSO_DATABASE_URL=libsql://your-database-name-your-org.turso.io
TURSO_AUTH_TOKEN=your-auth-token-here

# OpenAI Configuration (optional)
# Required for OpenAI embeddings (text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002)
OPENAI_API_KEY=your-openai-api-key-here

# Together AI Configuration (optional)
# Required for Together AI embeddings (m2-bert models)
TOGETHER_API_KEY=your-together-api-key-here

# GitHub Configuration (optional)
# Required for private GitHub repositories or to increase rate limits
GITHUB_TOKEN=your-github-token-here

# Deployment stage eg (local, dev, prod)
STAGE=your-deployment-stage

# Chunker Configuration
# Tokenizer encoding for text chunking - determines how text is split into tokens
# Options: cl100k_base (GPT-3.5/4), p50k_base (GPT-3), r50k_base (Codex)
CHUNKER_TOKENIZER=cl100k_base

# Default maximum tokens per chunk - controls chunk size for document splitting
# Smaller values create more granular chunks, larger values preserve more context
CHUNKER_DEFAULT_MAX_TOKENS=100

# Default overlap tokens for overlapping chunks - maintains context between chunks
# Should be less than CHUNKER_DEFAULT_MAX_TOKENS, typically 10-25% of max tokens
CHUNKER_DEFAULT_OVERLAP_TOKENS=20

# Chunker logging level - controls verbosity of chunker operations
# Options: debug (verbose), info (normal), warn (warnings only), error (errors only)
CHUNKER_LOG_LEVEL=error